{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperSpy Fitting tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows the basics of model (currently only 1D) fitting in HyperSpy from the grounds up.\n",
    "\n",
    "__Minimum required version:__ HyperSpy 1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors:\n",
    "\n",
    "- 13/04/2015 Tomas Ostasevicius - Developed for HyperSpy workshop at University of Cambridge\n",
    "- 01/06/2016 Tomas Ostasevicius - updated and expanded for HyperSpy workshop at Scandem conference 2016\n",
    "- 22/07/2016 Tomas Ostasevicius - updated for HyperSpy version 1.0\n",
    "- 19/04/2021 Francisco de la Peña - new synthetic dataset. Add standard deviation discussion.\n",
    "- 20/04/2021 Francisco de la Peña - Tweak dataset to always fail with `iterpath=\"flyback\"`. Add bounds, fixing parameters and standard deviation check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='terms'></a>\n",
    "## Terminology and relationships\n",
    "<a href='#top'>[back to top]</a> \n",
    "\n",
    "In order to use fitting in HyperSpy more effectively, it is useful to understand our structure for curve fitting.\n",
    "\n",
    "There are three main things, related to fitting:\n",
    "\n",
    "__1. Model__\n",
    "can be thought of as a simple box (cooking pot), where we have to put our ingredients. Without anything inside, it is not of much use in this case. Once we add some things to it and mix it a bit (do the actual fitting), however, we have our complete dish!\n",
    "\n",
    "__2. Component__ is the main building block (ingredient) of our model. Here we mix and match what components we need (or want) for the particular case of signal. \n",
    "\n",
    "Examples: \n",
    "- Lorentzian (Cauchy)\n",
    "- Gaussian\n",
    "- Voigt (a combination of Lorentzian and Gaussian)\n",
    "- Offset (i.e. constant background)\n",
    "- Exponential function\n",
    "- ...\n",
    "- [create your own or use the very specialised ones!]\n",
    "\n",
    "Each of the components is ultimately just a function that has variables that change the (shape of the) output. Such a variable in HyperSpy is called a __parameter__. The model is built by combining *linearly* the components.\n",
    "\n",
    "\n",
    "__3. Parameter__ is the knob that the fitting routine adjusts for a good fit. Each component must include at least one parameter in order to be able to change when fitting. A parameter is also the object that we may limit or have to adjust when the result of the fit is not satisfactory. \n",
    "\n",
    "Ultimately, a parameter is the only important thing, as far as the fitting is concerned - components are just smart and convenient boxes to combine parameters into functions, and a model is just a box for a collection of components.\n",
    "\n",
    "For now, let's just keep the rough structure in our heads and look at other things!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "## Importing and exploring the relevant docstrings\n",
    "\n",
    "HyperSpy, like all other Python libraries, first has to be imported in your Python setup in order to be used.\n",
    "Once it is, all the relevant commands can be looped up using the autocompletion feature of the IPython. \n",
    "\n",
    "Lets import the HyperSpy and set up plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import hyperspy.api as hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once imported, all the HyperSpy commands are available via the \n",
    "> `hs.<something>`\n",
    "\n",
    "interface. You can also look for the help with any Python object like this\n",
    "> `help(<something>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hs.model.components1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loading'></a>\n",
    "## Loading the data and creating the model\n",
    "<a href='#top'>[back to top]</a> \n",
    "\n",
    "First you should have a spectrum (a particular kind of the `Signal` subclass!) you want to fit. Let's load a synthetic dataset with some curves named \n",
    "> `\"two_peaks.hspy\"`\n",
    "\n",
    "and have a look at it.\n",
    "\n",
    "If you can't load the dataset, it means you most likely have not generated it yet. Please run the two cells <a href='#two_peaks'>at the end</a> of the notebook to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hs.load(\"two_peaks.hspy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the dataset we notice that it consists of two peaks that at different points change position and height. In oder to measure the position, height and width of the two peaks at all position we will create a ``Model`` that consists of 2 gaussian functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='creating_model'></a>\n",
    "<a href='#top'>[back to top]</a> \n",
    "\n",
    "Creating a model now is simple - just pass the spectrum to the function \n",
    "> `model_reference = signal_reference.create_model()`\n",
    "\n",
    "Let's reference the model by \"`m`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = s.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look what's inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model is still empty. That will not always be the case - for some types of signals, an automatic background component is added when creating a model, hence it's always good to check.\n",
    "\n",
    "We can plot the model in exactly the same way as the signal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference from the model plot is that each data point is displayed individually. \n",
    "\n",
    "<a id='creating_components'></a>\n",
    "<a href='#top'>[back to top]</a> \n",
    "\n",
    "To do anything with the model, we should __create__ some __components__ and add them. Let's create two gaussians, referenced as \"g1\" and \"g2\":\n",
    "\n",
    "-----------------\n",
    "P.S.: keep in mind that creating a component is a function - hence there should be brackets at the end! Such as \n",
    "> `our_component_reference = hs.model.components1D.example_component()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = hs.model.components1D.GaussianHF()\n",
    "g2 = hs.model.components1D.GaussianHF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adding_comps'></a>\n",
    "<a href='#top'>[back to top]</a> \n",
    "\n",
    "... and __add the components to__ our __model__. For that there are generally two ways:\n",
    "\n",
    "Individually\n",
    "> `our_model_reference.append(our_component_reference)`\n",
    "\n",
    "or in lists (i.e. grouped by square brackets)\n",
    "> `our_model_reference.extend([first_component_reference, second_component_reference])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.extend([g1, g2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the model looks now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='renaming_components'></a>\n",
    "<a href='#top'>[back to top]</a> \n",
    "\n",
    "For our convenience we can __rename__ the __components__ as we choose, for example \"wide\" and \"narrow\" (note that the \"g1\" and \"g2\" are only references we created for them, not names of the components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1.name = \"wide\"\n",
    "g2.name = \"narrow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the model again to see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='checking_values'></a>\n",
    "<a href='#top'>[back to top]</a>\n",
    "\n",
    "To finally see the full structure (the one we looked at <a href='#terms'>here</a>), we can __print all of the parameter values__ of all components of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.print_current_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the values, we have to look inside the components for the parameters. It can simply be done by following the pattern:\n",
    "> `some_component_reference.parameter_name.value`\n",
    "\n",
    "In this case the component references are the __g1__ and __g2__, while parameter names are __centre__, __A__ and __sigma__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it is good practice to store the model so that, if something goes wrong, we can go back to this stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.store(name=\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.signal.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is another model stored in the signal, `ground truth`. We'll put it to use at end of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1.fwhm.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can access the component more conveniently using its name as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components.wide.fwhm.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setting_values'></a>\n",
    "<a href='#top'>[back to top]</a>\n",
    "\n",
    "We can __set parameter values__ in exactly the same way. Let set `g1` `sigma` value to 30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components.wide.fwhm.value = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.print_current_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we can also __set values \"in bulk\"__ for all components in the model. The required command is\n",
    "> `m.set_parameters_value`\n",
    "\n",
    "Set the area (\"A\" parameter) of both peaks to 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.set_parameters_value('height', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.print_current_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing the model and fitting a single spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by analyzing the data at one single pixel. For that we can using the same indexing syntax that we use for signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00 = m.inav[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.plot(plot_components=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to increase the chances of obtaining a good fit to the data, we must provide better starting parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do that interactively, using ``m.gui()`` or manually as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.components.narrow.centre.value = 60\n",
    "m00.components.wide.centre.value = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit (notice that the model got updated in the figure) looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the value of the parameters have changed to their optimal value. Also notice that the standard deviation has been estimated too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.print_current_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how to know how good is the fit? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once the fit was performed, chi-squared ($\\chi^2$), degrees of freedom and reduced chi-squared ($\\chi^2_\\nu$) of the fit are automatically calculated.\n",
    "\n",
    "They are accessible with, respectively:\n",
    "> `m2.chisq`\n",
    "\n",
    "> `m2.dof`\n",
    "\n",
    "> `m2.red_chisq`\n",
    "\n",
    "Let's have a look at reduced $\\chi^2$ by plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.red_chisq.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's far too big! (A good fit should have $a\\chi^2_\\nu$ of around 1.)\n",
    "\n",
    "The issue is that we haven't defined the variance of the noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.signal.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For that we can use the following ``Signal`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.signal.estimate_poissonian_noise_variance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit. Because the noise variance is available, HyperSpy will now perform weighted non-linear least squares automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.red_chisq.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.print_current_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the value of the parameters and their standard deviation has changed. The previous values were biased because we haven't defined the noise variance. These values should be more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain an even more accurate result by using the current model to better estimate the noise variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.signal.estimate_poissonian_noise_variance(expected_value=m00.as_signal())\n",
    "m00.fit()\n",
    "m00.print_current_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m00.red_chisq.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the first line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now analyze the first line before attempting to fit the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = m.inav[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the parameters of the first pixels that we have estimated are already set.\n",
    "\n",
    "Like before, we must estimate the noise variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.signal.estimate_poissonian_noise_variance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit the whole line we must use the ``multifit()`` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.multifit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.red_chisq.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.components.narrow.height.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, the height seems to vary between 30 and 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.components.narrow.centre.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the position varies sinusoidally between 40 and 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.components.narrow.fwhm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be any pattern in the variation of the FWHM, it seems to vary randomly around 6. Let's check if its standard variation to value ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.components.narrow.fwhm.as_signal().data.std() / ml.components.narrow.fwhm.as_signal().data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's around 5%, which, given the noisiness of the data, is consistent with this  parameter not varying at all,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.components.wide.fwhm.as_signal().data.std() / ml.components.wide.fwhm.as_signal().data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wide peaks std to value ratio is just .6%, therefore it is reasonable to think that this parameter is fixed too.\n",
    "\n",
    "More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the whole model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting, it is a good idea storing the current state of the model. In this way, if we do something wrong, we can always return to this state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.store(\"first line fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.signal.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.signal.estimate_poissonian_noise_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.multifit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of those warnings suggest that something has indeed gone wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.red_chisq.get_histogram().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large number of pixels with a high $\\chi_{\\nu}^2$ indicates that something is wrong with the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.red_chisq.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like something went wrong when jumping from the first line to the second, probably because the starting parameters copied from the last pixel of the first row do are not suitable for the first pixel of the second row. Let's restore the model and try fitting with a differing starting parameters strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.signal.models.restore(\"first line fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.multifit(iterpath=\"serpentine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.red_chisq.get_histogram().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.red_chisq.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that there is no contrast shows that this time the fit is good at all pixels in the dataset! This is because with `iterpath=\"serpentine\"` the fitting routine advances one row at the end of each row without retourning to the beginning of the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounds and fixed components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the the FWHM of the narrow component sometimes gets negative. It doesn't actually matter, but it makes plotting and analysis more challenging. To fix this issue we can constrain the FWHM of the gaussian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.signal.models.restore(\"first line fitted\")\n",
    "m.components.narrow.fwhm.bmin = 5.5\n",
    "m.components.narrow.fwhm.bmax = 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.multifit(bounded=True, iterpath=\"serpentine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.red_chisq.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked: there is no sign reversal in the narrow FWHM plot anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the histogram of the FWHM parameter of both peaks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components.narrow.fwhm.as_signal().get_histogram().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components.wide.fwhm.as_signal().get_histogram().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The peaky shape of the histogram suggests that the parameter variation is only due to noise. The asymmetry is typical of the bias induced by approximating the Poisson noise with a gaussian (i.e. using weighted least-squares instead of an unbiased estimator such as maximum likelihood).\n",
    "\n",
    "Let's fit again using maximum likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.multifit(optimizer=\"Nelder-Mead\", loss_function=\"ML-poisson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components.narrow.fwhm.as_signal().get_histogram().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components.wide.fwhm.as_signal().get_histogram().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the peaks are more symmetric, confirming that the biased loss function was the issue. Let's check their mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components.wide.fwhm.as_signal().data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components.narrow.fwhm.as_signal().data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very close to the actual values that in this case are 60 and 6. With this insight we can refit the model setting the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that it would have been better to fix the FWHM of the peaks, let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.store(\"fitted with ML-poisson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.signal.models.restore(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components.narrow.fwhm.value = 6\n",
    "m.components.narrow.fwhm.free = False\n",
    "m.components.wide.fwhm.value = 60\n",
    "m.components.wide.fwhm.free = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.signal.axes_manager.indices = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.components.narrow.centre.value = 60\n",
    "m.components.wide.centre.value = 50\n",
    "m.set_parameters_value(\"height\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.multifit(iterpath=\"serpentine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.red_chisq.get_histogram().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also insptect the standard deviation maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_centre_value = m.components.narrow.centre.as_signal()\n",
    "narrow_centre_std = m.components.narrow.centre.as_signal(field=\"std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs.plot.plot_images([narrow_centre_value, narrow_centre_std], label=[\"centre\", \"centre std\"], axes_decor=\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the standard deviation image has a contrast? Is that expected? If yes, what should it be correlated with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now verify that the standard deviation estimation is correct. We know that, if correct, 66% percent of the residuals must fall between a 1 standard deviation interval. Let's use this property to verify the result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth is actually stored in the signal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.signal.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_centre_gt = m.signal.models.restore(\"ground truth\").components.narrow.centre.as_signal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = (narrow_centre_gt - narrow_centre_value).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_in_1sigma = len(residuals[(residuals > -narrow_centre_std.data) & (residuals < narrow_centre_std.data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "100 * residuals_in_1sigma / np.prod(residuals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is very close to 66% percent, so it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix I: User define components interesting components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we have a slightly stranger signal that we want to fit, like this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hs.load('wobbly_peak.hspy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's (as the name implies) composed of a sinus + gaussian + 2nd degree polynomial. However we don't have a `sin` component in the in-build library, so we'll just write our own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin = hs.model.components1D.Expression('A*sin(b*x + c)',\n",
    "                                        name='sin',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then just create and add all the additional components we might need: a gaussian and a polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = s.create_model()\n",
    "gaus = hs.model.components1D.Gaussian()\n",
    "poly = hs.model.components1D.Polynomial(2)\n",
    "m.extend([sin, gaus, poly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.print_current_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial values do not seem to be very useful, so let's just plot the model, turn on the widgets, and we'll play until things seem close enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot()\n",
    "\n",
    "m.gui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then fit it and look at the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.print_current_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix II: Generating the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='two_peaks'></a>\n",
    "### Two peaks\n",
    "<a href='#top'>[back to top]</a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "\n",
    "domain = 32 #size of the square domain\n",
    "hfactor = 600\n",
    "cent = (domain//2, domain//2)\n",
    "y,x = np.ogrid[-cent[0]:domain-cent[0], -cent[1]:domain-cent[1]]\n",
    "\n",
    "def gaussian2d(x, y, A=1, x0=0, y0=0, sigmax=20, sigmay=10):\n",
    "    return A * np.exp(-((x-x0)**2 / 2 / sigmax ** 2 + (y-y0)**2 / 2 / sigmay ** 2))\n",
    "\n",
    "center_narrow = 50 + 10 * np.sin(3 * np.pi * x / domain) * np.cos(4 * np.pi * y / domain)\n",
    "center_wide = 50 + 10 * (-0.1 * np.sin(3 * np.pi * x / domain) * np.cos(4 * np.pi * y / domain))\n",
    "\n",
    "r = np.sqrt(x**2 + y**2)\n",
    "h_narrow = .5 * (.5 + np.sin(r)**2) * gaussian2d(x, y) *  hfactor\n",
    "h_wide = (.5 + np.cos(r)**2) * gaussian2d(x, y) *  hfactor\n",
    "\n",
    "s = hs.signals.Signal1D(np.ones((domain,domain, 1024)))\n",
    "s.metadata.General.title = 'Two gaussians'\n",
    "s.axes_manager[0].name = \"x\"\n",
    "s.axes_manager[0].units = \"nm\"\n",
    "s.axes_manager[1].name = \"y\"\n",
    "s.axes_manager[1].units = \"nm\"\n",
    "\n",
    "s.axes_manager[2].name = \"Energy\"\n",
    "s.axes_manager[2].name = \"eV\"\n",
    "s.axes_manager[2].scale = 0.1\n",
    "m0 = s.create_model()\n",
    "\n",
    "gs01 = hs.model.components1D.GaussianHF()\n",
    "gs01.name = \"wide\"\n",
    "m0.append(gs01)\n",
    "gs01.fwhm.value = 60\n",
    "gs01.centre.map['values'][:] = center_wide\n",
    "gs01.centre.map['is_set'][:] = True\n",
    "gs01.height.map['values'][:] = h_wide\n",
    "gs01.height.map['is_set'][:] = True\n",
    "\n",
    "gs02 = hs.model.components1D.GaussianHF()\n",
    "gs02.name = \"narrow\"\n",
    "m0.append(gs02)\n",
    "gs02.fwhm.value = 6\n",
    "gs02.centre.map['values'][:] = center_narrow\n",
    "gs02.centre.map['is_set'][:] = True\n",
    "gs02.height.map['values'][:] = h_narrow\n",
    "gs02.height.map['is_set'][:] = True\n",
    "s.data = m0.as_signal().data\n",
    "s.add_poissonian_noise(random_state=0)\n",
    "m0.store(\"ground truth\")\n",
    "s.save(\"two_peaks.hspy\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wobbly_peak'></a>\n",
    "### Wobbly peak\n",
    "<a href='#top'>[back to top]</a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "\n",
    "k = 1\n",
    "alpha = 15\n",
    "amp = 3\n",
    "\n",
    "gaus_position = 15\n",
    "gaus_width = 5\n",
    "gaus_A = 300\n",
    "\n",
    "gradient = 0.6\n",
    "offset= 3\n",
    "\n",
    "sin_component = hs.model.components1D.Expression('A * sin(k*x + alpha)', name='sin', k=k,\n",
    "                                               alpha=alpha, A=amp)\n",
    "gaus = hs.model.components1D.Gaussian(A=gaus_A, sigma=gaus_width, centre=gaus_position)\n",
    "\n",
    "poly = hs.model.components1D.Polynomial(1)\n",
    "\n",
    "poly.coefficients.value = (gradient, offset)\n",
    "\n",
    "axis = np.linspace(0, 30, 3000, dtype='double')\n",
    "\n",
    "result = sin_component.function(axis)+ gaus.function(axis) + poly.function(axis)\n",
    "s = hs.signals.Signal1D(result)\n",
    "s.axes_manager[0].name = 'x'\n",
    "s.axes_manager[0].scale = 0.1\n",
    "s.axes_manager[0].offset = 0\n",
    "\n",
    "s.metadata.General.author = 'Tomas Ostasevicius'\n",
    "s.metadata.General.title = 'Sin + poly(2) + Gaussian'\n",
    "s.save('wobbly_peak', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
